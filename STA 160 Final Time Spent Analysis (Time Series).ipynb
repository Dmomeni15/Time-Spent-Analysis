{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time as t\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "pd.to_datetime(\"2020-11-11 24:30:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate Date and Time\n",
    "df = pd.read_csv(\"time-log-clean-anon.csv\")\n",
    "print(df[df[\"Time\"]==\"2021-04-13 03:00:00\"])\n",
    "print(df.iloc[114960:114980,:])\n",
    "print(df.iloc[120070:120090,:])\n",
    "\n",
    "df2 = deepcopy(df)\n",
    "print(df2, \"\\n\", df2.shape)\n",
    "print(df2.columns)\n",
    "print(df2[\"Time\"].iloc[0], \"\\n====\\n\", type(df2[\"Time\"].iloc[0]))\n",
    "df2[\"Date\"] = df2[\"Time\"].apply(lambda x: x.split(\" \")[0])\n",
    "df2[\"Time\"] = df2[\"Time\"].apply(lambda x: x.split(\" \")[1])\n",
    "df2 = df2[[\"Date\", \"Time\", \"Activity\"]]\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing\n",
    "print(df2[\"Activity\"].unique())\n",
    "vals = [\"date\", \n",
    " 'break', 'breakfast', 'planning', '108', 'lunch', '131a', 'career', 'exercise',\n",
    " 'dinner', 'CLA', 'fys', 'appt', 'help', 'prep', '165a', '141a', '131b', '154a',\n",
    " 'UDCE', '302', '141b', '171', '106', '137', '167', 'bike', '168', 'walk', '131c',\n",
    " '010', '122a', 'bus', '135', '104', '141c', '130', '330', '141', '162', '160', '174']\n",
    "tmp = {vals[i]:0 for i in range(len(vals))}  # https://www.geeksforgeeks.org/python-convert-a-list-to-dictionary/\n",
    "print(tmp)\n",
    "print(df2[\"Activity\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some times are messed up and not mult's of 5; find them\n",
    "# There are also lots of breaks in the middle of the night...\n",
    "# ...this is because pandas sometimes takes the long way around\n",
    "for i, row in tqdm(df2.iterrows()):\n",
    "    #if pd.to_datetime(row.Time).minute%5 != 0:\n",
    "    if pd.to_datetime(row.Time).hour == 3:\n",
    "        print(row.Date, row.Time)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By time of day:\n",
    "by_min = pd.DataFrame()\n",
    "\n",
    "# Group the data by time slot\n",
    "for i, onetime in tqdm(df2.groupby(\"Time\")):\n",
    "    #print(i, type(i))\n",
    "    result = {vals[i]:0 for i in range(len(vals))}\n",
    "    for act in onetime[\"Activity\"]: \n",
    "        result[act] += 1\n",
    "    result[\"date\"] = i\n",
    "    by_min = by_min.append(result, ignore_index=True)\n",
    "print(by_min.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_min = by_min.groupby([\"date\"]).sum()\n",
    "# by_min.index.name = \"Time\"\n",
    "by_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something is off, with breaks in the middle of the night\n",
    "print(by_min.iloc[:10,:].sum())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =================  \n",
    "# from https://towardsdatascience.com/stacked-bar-charts-with-pythons-matplotlib-f4020e4eb4a7\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fields = ['break', 'breakfast', 'planning', '108', 'lunch', '131a', 'career', 'exercise',\n",
    " 'dinner', 'CLA', 'fys', 'appt', 'help', 'prep', '165a', '141a', '131b', '154a',\n",
    " 'UDCE', '302', '141b', '171', '106', '137', '167', 'bike', '168', 'walk', '131c',\n",
    " '010', '122a', 'bus', '135', '104', '141c', '130', '330', '141', '162', '160', '174']\n",
    "# TODO:\n",
    "#colors = ['#1D2F6F', '#8390FA', '#6EAF46', '#FAC748']\n",
    "labels = ['brk', 'bft', 'pln', '108', 'lun', '131a', 'crr', 'xrc',\n",
    " 'din', 'cla', 'fys', 'apt', 'help', 'prep', '165a', '141a', '131b', '154a',\n",
    " 'udce', '302', '141b', '171', '106', '137', '167', 'bike', '168', 'walk', '131c',\n",
    " '010', '122a', 'bus', '135', '104', '141c', '130', '330', '141', '162', '160', '174']\n",
    "# figure and axis\n",
    "fig, ax = plt.subplots(1, figsize=(12, 50))\n",
    "# plot bars\n",
    "left = len(by_min) * [0]\n",
    "for idx, name in tqdm(enumerate(fields)):\n",
    "    plt.barh(by_min.index, by_min[name], left = left) #, color=colors[idx])\n",
    "    left = left + by_min[name]\n",
    "# title, legend, labels\n",
    "plt.title('Activity by Time of Day\\n', loc='left')\n",
    "plt.legend(labels, bbox_to_anchor=([0.55, 1, 0, 0]), ncol=4, frameon=False)\n",
    "plt.xlabel('Time spent')\n",
    "# remove spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "# adjust limits and draw grid lines\n",
    "# f = plt.figure()\n",
    "# f.set_size_inches(10,120)\n",
    "# plt.ylim(-0.5, ax.get_yticks()[-1] + 0.5)\n",
    "# ax.set_axisbelow(True)\n",
    "# ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_one_thirty_five_ts = by_min\n",
    "sta_one_thirty_five_ts = sta_one_thirty_five_ts.drop(['bus', 'CLA', 'dinner', 'exercise', 'fys', 'help', 'lunch', 'planning', 'prep', 'walk', 'UDCE', 'appt', 'bike', 'break', 'breakfast', '174', '160', '131c', '130', '168', '141', '167', '165a', '154a', '302', '162', '131b', '131a', '141b', '141a', '137', '010', '122a', '108', '171', '330', '141c', '106', '104', 'career'], axis = 1)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,6\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('135')\n",
    "plt.plot(sta_one_thirty_five_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rolling statistics\n",
    "\n",
    "rolmean = sta_one_thirty_five_ts.rolling(window=12).mean()\n",
    "rolstd = sta_one_thirty_five_ts.rolling(window=12).std()\n",
    "print(rolmean, rolstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = plt.plot(sta_one_thirty_five_ts, color = 'pink', label = 'Original')\n",
    "mean = plt.plot(rolmean, color = 'purple', label = 'Rolling Mean')\n",
    "std = plt.plot(rolstd, color = 'red', label = \"Rolling Std\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Rolling Mean and Std')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "print('Results of the Dickey-Fuller Test:')\n",
    "dftest = adfuller(sta_one_thirty_five_ts['135'], autolag = 'AIC')\n",
    "\n",
    "dfoutput = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "    \n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_one_thirty_five_ts_log = np.log(sta_one_thirty_five_ts)\n",
    "plt.plot(sta_one_thirty_five_ts_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movingAverage = sta_one_thirty_five_ts_log.rolling(window=12).mean()\n",
    "movingSTD = sta_one_thirty_five_ts_log.rolling(window=12).std()\n",
    "plt.plot(sta_one_thirty_five_ts_log)\n",
    "plt.plot(movingAverage, color = 'pink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLogMinusMovingAvg = sta_one_thirty_five_ts_log - movingAverage\n",
    "\n",
    "#Remove NA Values\n",
    "dfLogMinusMovingAvg.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "    movingAverage = timeseries.rolling(window=12).mean()\n",
    "    movingSTD = timeseries.rolling(window=12).std()\n",
    "    \n",
    "    orig = plt.plot(timeseries, color = 'pink', label = 'Original')\n",
    "    mean = plt.plot(movingAverage, color = 'purple', label = 'Rolling Mean')\n",
    "    std = plt.plot(movingSTD, color = 'red', label = 'Rolling STD')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries['135'], autolag = 'AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index = ['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used' ])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(dfLogMinusMovingAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponentialDecayWeightedAverage = sta_one_thirty_five_ts_log.ewm(halflife=12, min_periods=0, adjust = True).mean()\n",
    "plt.plot(sta_one_thirty_five_ts_log)\n",
    "plt.plot(exponentialDecayWeightedAverage, color = 'pink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLogMinusMovingExpDecayAvg = sta_one_thirty_five_ts_log - exponentialDecayWeightedAverage\n",
    "test_stationarity(dfLogMinusMovingExpDecayAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLogDiffShift = sta_one_thirty_five_ts_log - sta_one_thirty_five_ts_log.shift()\n",
    "plt.plot(dfLogDiffShift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLogDiffShift.dropna(inplace = True)\n",
    "test_stationarity(dfLogDiffShift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLogDiffShift.isnull().sum()\n",
    "dfLogDiffShift.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLogDiffShift.dropna(inplace = True)\n",
    "test_stationarity(dfLogDiffShift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "lag_acf = acf(dfLogMinusMovingAvg, nlags = 20)\n",
    "lag_pacf = pacf(dfLogMinusMovingAvg, nlags=20, method = 'ols')\n",
    "\n",
    "#Plot ACF\n",
    "plt.subplot(121)\n",
    "plt.plot(lag_acf)\n",
    "plt.axhline(y=0, linestyle='--', color = 'pink')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(dfLogDiffShift)), linestyle='--', color = 'pink')\n",
    "plt.axhline(y=1.96/np.sqrt(len(dfLogDiffShift)), linestyle='--', color = 'pink')\n",
    "plt.title('Autocorrelation Function')\n",
    "\n",
    "#Plot PACF\n",
    "plt.subplot(122)\n",
    "plt.plot(lag_pacf)\n",
    "plt.axhline(y=0, linestyle='--', color = 'pink')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(dfLogDiffShift)), linestyle='--', color = 'pink')\n",
    "plt.axhline(y=1.96/np.sqrt(len(dfLogDiffShift)), linestyle='--', color = 'pink')\n",
    "plt.title('Partial Autocorrelation Function')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "#AR model\n",
    "model = ARIMA(dfLogMinusMovingAvg, order =(2,1,7))\n",
    "results_AR = model.fit(disp=-1)\n",
    "plt.plot(dfLogMinusMovingAvg)\n",
    "plt.plot(results_AR.fittedvalues, color ='red')\n",
    "plt.title('RSS: %4f'% sum((results_AR.fittedvalues-dfLogMinusMovingAvg['135'])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# convert into x and y\n",
    "x = list(range(len(by_min.index)))\n",
    "y = by_min\n",
    "\n",
    "# plot the co2 data\n",
    "fig = plt.figure()\n",
    "plt.plot(x,y)\n",
    "plt.ylabel('Activity')\n",
    "plt.xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# apply fast fourier transform and take absolute values\n",
    "f=abs(np.fft.fft(y))\n",
    "\n",
    "# get the list of frequencies\n",
    "num=np.size(x)\n",
    "freq = [i / num for i in list(range(num))]\n",
    "\n",
    "# get the list of spectrums\n",
    "spectrum=f.real*f.real+f.imag*f.imag\n",
    "nspectrum=spectrum/spectrum[0]\n",
    "\n",
    "# plot nspectrum per frequency, with a semilog scale on nspectrum\n",
    "plt.semilogy(freq,nspectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=1/(52*7*24*(60/5))\n",
    "\n",
    "import pandas as pd\n",
    "results = pd.DataFrame({'freq': freq, 'nspectrum': nspectrum})\n",
    "results['period'] = results['freq'] / test\n",
    "plt.semilogy(results['period'], results['nspectrum'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve the plot by convertint the data into grouped per week to avoid peaks\n",
    "results['period_round'] = results['period'].round()\n",
    "grouped_week = results.groupby('period_round')['nspectrum'].sum()\n",
    "plt.semilogy(grouped_week.index, grouped_week)\n",
    "plt.xticks([1, 13, 26, 39, 52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_im = by_min\n",
    "ft_im = ft_im.drop(['bus', 'CLA', 'dinner', 'exercise', 'fys', 'help', 'lunch', 'planning', 'prep', 'walk'], axis = 1)\n",
    "ft_im = ft_im.drop(['UDCE', 'appt', 'bike', 'break', 'breakfast'], axis = 1)\n",
    "ft_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 14,7\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "ss = StandardScaler()\n",
    "label_quality = LabelEncoder()\n",
    "\n",
    "ft_im['career'] = label_quality.fit_transform(ft_im['career'])\n",
    "\n",
    "X = ft_im.drop('career', axis = 1)\n",
    "y = ft_im['career']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =.25, random_state = 42)\n",
    "\n",
    "X_tr_sc = ss.fit_transform(X_train)\n",
    "X_te_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_tr_sc, y_train)\n",
    "importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': model.coef_[0]\n",
    "})\n",
    "\n",
    "importances = importances.sort_values(by='Importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=importances[\"Attribute\"], height = importances['Importance'], color = 'pink')\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
